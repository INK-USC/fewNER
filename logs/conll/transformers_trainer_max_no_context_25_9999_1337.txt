device: cuda:0
seed: 1337
dataset: conll
data_dir: dataset/conll
percent_filename_suffix: 25_9999
optimizer: adamw
learning_rate: 2e-05
momentum: 0.0
l2: 1e-08
lr_decay: 0
batch_size: 4
num_epochs: 50
train_num: -1
dev_num: -1
test_num: -1
max_no_incre: 20
max_grad_norm: 1.0
checkpoint: 
model_folder: models/conll/transformers_trainer_max_no_context_25_9999_1337
hidden_dim: 0
dropout: 0.5
embedder_type: bert-base-cased
parallel_embedder: 0
add_iobes_constraint: 0
mode: train
test_file: data/conll2003_sample/test.txt
percentage: 100
prompt: max
template: no_context
search_pool: None
using GPU... 0
[34m[Data Info] Tokenizing the instances using 'bert-base-cased' tokenizer[0m
[34m[Data Info] Reading dataset from: 
dataset/conll/train_25_9999.txt
dataset/conll/dev.txt
dataset/conll/test.txt[0m
[Data Info] Reading file: dataset/conll/train_25_9999.txt, labels will be converted to IOBES encoding
[Data Info] Modify src/data/transformers_dataset.read_txt function if you have other requirements
number of sentences: 25
[Data Info] Using the training set to build label index
#labels: 20
label 2idx: {'<PAD>': 0, 'B-MISC': 1, 'E-MISC': 2, 'O': 3, 'B-PER': 4, 'E-PER': 5, 'B-LOC': 6, 'I-LOC': 7, 'E-LOC': 8, 'S-MISC': 9, 'S-ORG': 10, 'S-LOC': 11, 'B-ORG': 12, 'E-ORG': 13, 'I-PER': 14, 'I-ORG': 15, 'S-PER': 16, 'I-MISC': 17, '<START>': 18, '<STOP>': 19}
[31mSome sample prompts used: [0m
[34mInstance 0: ['CENTRAL', 'DIVISION'][0m
[33mPrompt 0: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 2: ['More', 'than', '20,000', 'people', 'have', 'been', 'killed', 'in', 'the', '12-year-old', 'conflict', 'between', 'Turkish', 'troops', 'and', 'PKK', 'guerrillas', 'fighting', 'for', 'autonomy', 'or', 'independence', 'from', 'Turkey', '.'][0m
[33mPrompt 2: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 4: ['Hurte', 'Sierd', 'Zylstra', 'and', 'his', 'wife', ',', 'Jetsi', 'Hendrika', 'Coers', ',', 'both', '50', ',', 'were', 'abducted', 'from', 'the', 'teak', 'plantation', 'they', 'managed', 'late', 'Saturday', 'or', 'early', 'Sunday', 'by', 'at', 'least', 'two', 'men', 'demanding', '$', '1.5', 'million', 'ransom', ',', 'authorities', 'said', '.'][0m
[33mPrompt 4: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 6: ['NEW', 'YORK', '1996-08-29'][0m
[33mPrompt 6: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 8: ['A.', 'Stewart', 'not', 'out', '40'][0m
[33mPrompt 8: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 10: ['"', 'Coming', 'just', 'a', 'million', 'guilders', 'under', 'the', 'forecast', 'range', 'is', "n't", 'overwhelmingly', 'surprising', ',', '"', 'said', 'ING', 'analyst', 'Steven', 'Vrolijk', ',', 'who', 'is', 'continuing', 'to', 'look', 'for', 'a', 'nine', 'to', '10', 'percent', 'rise', 'in', '1996', 'earnings', '.'][0m
[33mPrompt 10: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 12: ['WESTERN', 'DIVISION'][0m
[33mPrompt 12: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 14: ['1', '-', 'Michael', 'Chang', '(', 'U.S.', ')', 'beat', 'Sergi', 'Bruguera', '(', 'Spain', ')', '6-3', '6-2'][0m
[33mPrompt 14: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 16: ['He', 'added', ':', '"', 'It', "'s", 'very', 'sad', 'to', 'beat', 'Henry', 'Candy', 'because', 'I', 'am', 'godfather', 'to', 'his', 'daughter', '.', '"'][0m
[33mPrompt 16: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 18: ['His', 'supporters', 'will', 'contest', 'the', 'parliamentary', 'election', 'in', 'a', 'coalition', 'of', '30', 'mainly', 'small', 'parties', ',', 'the', 'Republican', 'Front', ',', 'led', 'by', 'Deby', "'s", 'Patriotic', 'Salvation', 'Movement', '.'][0m
[33mPrompt 18: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 20: ['Chairman', 'Mohamed', 'Fahim', 'Rayyan', 'told', 'a', 'news', 'conference', 'at', 'Cairo', 'airport', ':', '"', 'The', 'control', 'tower', 'should', 'have', 'allocated', 'the', 'plane', 'another', 'runway', ',', 'instead', 'of', 'the', 'one', 'the', 'plane', 'landed', 'on', '.', '"'][0m
[33mPrompt 20: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 22: ['--', 'Cleveland', 'Newsdesk', '216-579-0077'][0m
[33mPrompt 22: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 24: ['NEC', 'Nijmegen', '0', 'AZ', 'Alkmaar', '0'][0m
[33mPrompt 24: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[Data Info] Reading file: dataset/conll/train_25_9999.txt, labels will be converted to IOBES encoding
[Data Info] Modify src/data/transformers_dataset.read_txt function if you have other requirements
number of sentences: 25
[Data Info] Using the training set to build label index
#labels: 20
label 2idx: {'<PAD>': 0, 'B-MISC': 1, 'E-MISC': 2, 'O': 3, 'B-PER': 4, 'E-PER': 5, 'B-LOC': 6, 'I-LOC': 7, 'E-LOC': 8, 'S-MISC': 9, 'S-ORG': 10, 'S-LOC': 11, 'B-ORG': 12, 'E-ORG': 13, 'I-PER': 14, 'I-ORG': 15, 'S-PER': 16, 'I-MISC': 17, '<START>': 18, '<STOP>': 19}
[31mSome sample prompts used: [0m
[34mInstance 0: ['CENTRAL', 'DIVISION'][0m
[33mPrompt 0: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 2: ['More', 'than', '20,000', 'people', 'have', 'been', 'killed', 'in', 'the', '12-year-old', 'conflict', 'between', 'Turkish', 'troops', 'and', 'PKK', 'guerrillas', 'fighting', 'for', 'autonomy', 'or', 'independence', 'from', 'Turkey', '.'][0m
[33mPrompt 2: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 4: ['Hurte', 'Sierd', 'Zylstra', 'and', 'his', 'wife', ',', 'Jetsi', 'Hendrika', 'Coers', ',', 'both', '50', ',', 'were', 'abducted', 'from', 'the', 'teak', 'plantation', 'they', 'managed', 'late', 'Saturday', 'or', 'early', 'Sunday', 'by', 'at', 'least', 'two', 'men', 'demanding', '$', '1.5', 'million', 'ransom', ',', 'authorities', 'said', '.'][0m
[33mPrompt 4: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 6: ['NEW', 'YORK', '1996-08-29'][0m
[33mPrompt 6: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 8: ['A.', 'Stewart', 'not', 'out', '40'][0m
[33mPrompt 8: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 10: ['"', 'Coming', 'just', 'a', 'million', 'guilders', 'under', 'the', 'forecast', 'range', 'is', "n't", 'overwhelmingly', 'surprising', ',', '"', 'said', 'ING', 'analyst', 'Steven', 'Vrolijk', ',', 'who', 'is', 'continuing', 'to', 'look', 'for', 'a', 'nine', 'to', '10', 'percent', 'rise', 'in', '1996', 'earnings', '.'][0m
[33mPrompt 10: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 12: ['WESTERN', 'DIVISION'][0m
[33mPrompt 12: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 14: ['1', '-', 'Michael', 'Chang', '(', 'U.S.', ')', 'beat', 'Sergi', 'Bruguera', '(', 'Spain', ')', '6-3', '6-2'][0m
[33mPrompt 14: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 16: ['He', 'added', ':', '"', 'It', "'s", 'very', 'sad', 'to', 'beat', 'Henry', 'Candy', 'because', 'I', 'am', 'godfather', 'to', 'his', 'daughter', '.', '"'][0m
[33mPrompt 16: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 18: ['His', 'supporters', 'will', 'contest', 'the', 'parliamentary', 'election', 'in', 'a', 'coalition', 'of', '30', 'mainly', 'small', 'parties', ',', 'the', 'Republican', 'Front', ',', 'led', 'by', 'Deby', "'s", 'Patriotic', 'Salvation', 'Movement', '.'][0m
[33mPrompt 18: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 20: ['Chairman', 'Mohamed', 'Fahim', 'Rayyan', 'told', 'a', 'news', 'conference', 'at', 'Cairo', 'airport', ':', '"', 'The', 'control', 'tower', 'should', 'have', 'allocated', 'the', 'plane', 'another', 'runway', ',', 'instead', 'of', 'the', 'one', 'the', 'plane', 'landed', 'on', '.', '"'][0m
[33mPrompt 20: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 22: ['--', 'Cleveland', 'Newsdesk', '216-579-0077'][0m
[33mPrompt 22: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 24: ['NEC', 'Nijmegen', '0', 'AZ', 'Alkmaar', '0'][0m
[33mPrompt 24: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[Data Info] Reading file: dataset/conll/dev.txt, labels will be converted to IOBES encoding
[Data Info] Modify src/data/transformers_dataset.read_txt function if you have other requirements
number of sentences: 2601
[31mSome sample prompts used: [0m
[34mInstance 0: ['CRICKET', '-', 'LEICESTERSHIRE', 'TAKE', 'OVER', 'AT', 'TOP', 'AFTER', 'INNINGS', 'VICTORY', '.'][0m
[33mPrompt 0: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 260: ['"', 'Randall', 'was', 'one', 'of', 'the', 'most', 'exciting', 'quarterbacks', 'in', 'NFL', 'history', ',', '"', 'said', 'Eagles', 'owner', 'Jeffrey', 'Lurie', '.', '"'][0m
[33mPrompt 260: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 520: ['CRICKET', '-', 'AUSTRALIA', '228-9', 'IN', '50', 'OVERS', 'V', 'SRI', 'LANKA', '.'][0m
[33mPrompt 520: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 780: ['BOGOTA', ',', 'Colombia', '1996-08-30'][0m
[33mPrompt 780: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 1040: ['CAIRO', '1996-08-30'][0m
[33mPrompt 1040: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 1300: ['2.', 'Giovanni', 'Lombardi', '(', 'Italy', ')', 'Polti', '5', 'seconds', 'behind'][0m
[33mPrompt 1300: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 1560: ['Oxford', '4', '1', '0', '3', '6', '5', '3'][0m
[33mPrompt 1560: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 1820: ['MINSK', '1996-08-31'][0m
[33mPrompt 1820: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 2080: ['Belgium', "'s", 'best', 'second-half', 'effort', 'came', 'three', 'minutes', 'later', 'when', 'Degryse', 'put', 'the', 'ball', 'over', 'the', 'bar', 'from', 'close', 'range', 'with', 'Recber', 'beaten', '.'][0m
[33mPrompt 2080: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 2340: ['Gonzalo', 'Montoya', ',', 'a', 'police', 'commander', 'in', 'Tacambaro', ',', 'told', 'Radio', 'Red', 'the', 'group', 'was', 'armed', 'with', 'AK-47s', 'and', 'other', 'high-powered', 'assault', 'rifles', 'and', 'wore', 'military-style', 'fatigues', '.'][0m
[33mPrompt 2340: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[34mInstance 2600: ['--', 'Dhaka', 'Newsroom', '880-2-506363'][0m
[33mPrompt 2600: ['CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'MISC', '.', '[SEP]', 'A', '##byss', 'De', '##J', '##es', '##us', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Christopher', 'Children', "'", 's', 'Hospital', 'is', 'LOC', '.', '[SEP]', 'P', '##K', '##K', 'is', 'ORG', '.', '[SEP]']
[0m
[Data Info] Reading file: dataset/conll/test.txt, labels will be converted to IOBES encoding
[Data Info] Modify src/data/transformers_dataset.read_txt function if you have other requirements
number of sentences: 2746
[31mSome sample prompts used: [0m
[34mInstance 0: ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.'][0m
[33mPrompt 0: ['Michael', 'Chang', 'is', 'PER', '.', '[SEP]', 'A', '.', 'Stewart', 'is', 'LOC', '.', '[SEP]', 'Santiago', 'Bern', '##abe', '##u', 'is', 'ORG', '.', '[SEP]', 'NE', '##W', 'Y', '##OR', '##K', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 274: ['West', 'Indies', '-', 'Sherwin', 'Campbell', ',', 'Robert', 'Samuels', ',', 'Brian', 'Lara', ',', 'Shivnarine', 'Chanderpaul', ',', 'Carl', 'Hooper', ',', 'Jimmy', 'Adams', ',', 'Junior', 'Murray', ',', 'Nixon', 'McLean', ',', 'Kenneth', 'Benjamin', ',', 'Curtly', 'Ambrose', ',', 'Courtney', 'Walsh', '(', 'captain', ')', ',', 'Roland', 'Holder', '12th', 'man', '.'][0m
[33mPrompt 274: ['Bayern', 'Munich', 'is', 'PER', '.', '[SEP]', 'Marc', 'Du', '##tro', '##ux', 'is', 'LOC', '.', '[SEP]', 'Michael', 'Chang', 'is', 'ORG', '.', '[SEP]', 'Sea', '##ford', 'Union', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 548: ['Montpellier', '20', '3', '9', '8', '17', '24', '18'][0m
[33mPrompt 548: ['Turkish', 'is', 'PER', '.', '[SEP]', 'U', '.', 'S', '.', 'is', 'LOC', '.', '[SEP]', 'Scarborough', 'is', 'ORG', '.', '[SEP]', 'Ser', '##gi', 'B', '##rug', '##uer', '##a', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 822: ['Edna', 'Fernandes'][0m
[33mPrompt 822: ['NE', '##W', 'Y', '##OR', '##K', 'is', 'PER', '.', '[SEP]', 'Bayern', 'Munich', 'is', 'LOC', '.', '[SEP]', 'R', '##och', '##dale', 'is', 'ORG', '.', '[SEP]', 'Henry', 'Candy', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 1096: ['Yeltsin', 'has', 'been', 'shown', 'a', 'few', 'times', 'on', 'television', 'since', 'his', 'quintuple', 'bypass', 'on', 'November', '5', 'but', 'has', 'yet', 'to', 'deliver', 'any', 'major', 'television', 'or', 'radio', 'address', 'to', 'the', 'nation', '.'][0m
[33mPrompt 1096: ['Patriotic', 'Salvation', 'Movement', 'is', 'PER', '.', '[SEP]', 'Andy', 'Ben', '##es', 'is', 'LOC', '.', '[SEP]', 'Steven', 'V', '##rol', '##i', '##jk', 'is', 'ORG', '.', '[SEP]', 'Human', 'Gene', 'Therapy', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 1370: ['Minneapolis', '306,364', '153,231'][0m
[33mPrompt 1370: ['Thai', 'is', 'PER', '.', '[SEP]', 'Houston', 'Astros', 'is', 'LOC', '.', '[SEP]', 'CE', '##NT', '##RA', '##L', 'D', '##I', '##VI', '##SI', '##ON', 'is', 'ORG', '.', '[SEP]', 'De', '##by', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 1644: ['--', 'Frankfurt', 'Newsroom', ',', '+49', '69', '756525'][0m
[33mPrompt 1644: ['Mohamed', 'F', '##ahi', '##m', 'Ray', '##yan', 'is', 'PER', '.', '[SEP]', 'St', '.', 'Louis', 'Cardinals', 'is', 'LOC', '.', '[SEP]', 'Thai', 'is', 'ORG', '.', '[SEP]', 'NE', '##W', 'Y', '##OR', '##K', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 1918: ['18.', 'Barbara', 'Merlin', '(', 'Italy', ')', '92'][0m
[33mPrompt 1918: ['A', '##Z', 'Al', '##k', '##ma', '##ar', 'is', 'PER', '.', '[SEP]', 'Athens', 'News', '##room', 'is', 'LOC', '.', '[SEP]', 'Cleveland', 'News', '##des', '##k', 'is', 'ORG', '.', '[SEP]', 'At', '##let', '##ico', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 2192: ['Coleraine', '10', '7', '1', '2', '18', '11', '22'][0m
[33mPrompt 2192: ['Marc', 'Du', '##tro', '##ux', 'is', 'PER', '.', '[SEP]', 'Human', 'Gene', 'Therapy', 'is', 'LOC', '.', '[SEP]', 'Michael', 'Chang', 'is', 'ORG', '.', '[SEP]', 'Scarborough', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 2466: ['Australia', '-', 'Tries', ':', 'Matthew', 'Burke', '(', '2', ')', ',', 'Joe', 'Roff', ',', 'David', 'Campese', ',', 'Tim', 'Horan', '.'][0m
[33mPrompt 2466: ['NE', '##W', 'Y', '##OR', '##K', 'is', 'PER', '.', '[SEP]', 'Cairo', 'is', 'LOC', '.', '[SEP]', 'Houston', 'is', 'ORG', '.', '[SEP]', 'R', '##och', '##dale', 'is', 'MISC', '.', '[SEP]']
[0m
[34mInstance 2740: ['"', 'The', 'years', 'I', 'spent', 'as', 'manager', 'of', 'the', 'Republic', 'of', 'Ireland', 'were', 'the', 'best', 'years', 'of', 'my', 'life', '.'][0m
[33mPrompt 2740: ['Amsterdam', 'is', 'PER', '.', '[SEP]', 'Nepali', 'is', 'LOC', '.', '[SEP]', 'Real', 'Madrid', 'is', 'ORG', '.', '[SEP]', 'Amsterdam', 'is', 'MISC', '.', '[SEP]']
[0m
[Data Info] number of training instances: 7
[31m[Model Info]: Working with transformers package from huggingface with bert-base-cased[0m
[31m[Optimizer Info]: You should be aware that you are using the optimizer from huggingface.[0m
[31m[Optimizer Info]: Change the optimier in transformers_util.py if you want to make some modifications.[0m
[31m[Model Info] Loading pretrained language model bert-base-cased[0m
[33mUsing AdamW optimizeer by HuggingFace with 2e-05 learning rate, eps: 1e-08, weight decay: 0.0, warmup_step: 0, [0m
[31m[Optimizer Info] Modify the optimizer info as you need.[0m
AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 2e-05
    lr: 2e-05
    weight_decay: 0.0
)
[Info] The model will be saved to: models/conll/transformers_trainer_max_no_context_25_9999_1337.tar.gz
[31m[Train Info] Start training, you have set to stop if performace not increase for 20 epochs[0m
Epoch 1: 1638.05561, Time is 2.15s
[34m[dev set Total] Prec.: 0.14, Rec.: 0.47, F1: 0.22[0m
saving the best model...
Epoch 2: 782.38094, Time is 1.88s
[34m[dev set Total] Prec.: 0.00, Rec.: 0.00, F1: 0.00[0m
Epoch 3: 516.64651, Time is 2.09s
[34m[dev set Total] Prec.: 0.00, Rec.: 0.00, F1: 0.00[0m
Epoch 4: 413.71284, Time is 1.99s
[34m[dev set Total] Prec.: 0.60, Rec.: 0.35, F1: 0.44[0m
saving the best model...
Epoch 5: 336.39885, Time is 1.92s
[34m[dev set Total] Prec.: 3.30, Rec.: 2.41, F1: 2.78[0m
saving the best model...
Epoch 6: 286.24559, Time is 1.19s
[34m[dev set Total] Prec.: 6.32, Rec.: 4.24, F1: 5.08[0m
saving the best model...
Epoch 7: 246.90701, Time is 1.88s
[34m[dev set Total] Prec.: 18.82, Rec.: 9.58, F1: 12.70[0m
saving the best model...
Epoch 8: 197.62692, Time is 1.59s
[34m[dev set Total] Prec.: 30.38, Rec.: 19.84, F1: 24.00[0m
saving the best model...
Epoch 9: 163.29639, Time is 1.98s
[34m[dev set Total] Prec.: 37.15, Rec.: 27.65, F1: 31.70[0m
saving the best model...
Epoch 10: 133.93336, Time is 1.86s
[34m[dev set Total] Prec.: 42.39, Rec.: 33.68, F1: 37.54[0m
saving the best model...
Epoch 11: 107.23171, Time is 1.96s
[34m[dev set Total] Prec.: 45.63, Rec.: 37.23, F1: 41.01[0m
saving the best model...
Epoch 12: 87.17406, Time is 1.88s
[34m[dev set Total] Prec.: 45.57, Rec.: 37.93, F1: 41.40[0m
saving the best model...
Epoch 13: 67.48477, Time is 1.92s
[34m[dev set Total] Prec.: 48.29, Rec.: 40.23, F1: 43.90[0m
saving the best model...
Epoch 14: 53.98529, Time is 1.92s
[34m[dev set Total] Prec.: 50.79, Rec.: 43.31, F1: 46.76[0m
saving the best model...
Epoch 15: 45.46768, Time is 1.88s
[34m[dev set Total] Prec.: 52.09, Rec.: 43.77, F1: 47.57[0m
saving the best model...
Epoch 16: 35.26632, Time is 1.91s
[34m[dev set Total] Prec.: 52.45, Rec.: 44.53, F1: 48.16[0m
saving the best model...
Epoch 17: 30.12137, Time is 1.88s
[34m[dev set Total] Prec.: 54.12, Rec.: 45.98, F1: 49.72[0m
saving the best model...
Epoch 18: 24.11673, Time is 1.86s
[34m[dev set Total] Prec.: 52.53, Rec.: 46.62, F1: 49.40[0m
Epoch 19: 20.26257, Time is 1.83s
[34m[dev set Total] Prec.: 53.17, Rec.: 46.53, F1: 49.63[0m
Epoch 20: 16.29489, Time is 2.21s
[34m[dev set Total] Prec.: 54.95, Rec.: 47.29, F1: 50.83[0m
saving the best model...
Epoch 21: 13.82943, Time is 1.90s
[34m[dev set Total] Prec.: 56.43, Rec.: 47.57, F1: 51.63[0m
saving the best model...
Epoch 22: 11.17502, Time is 1.76s
[34m[dev set Total] Prec.: 56.51, Rec.: 47.66, F1: 51.71[0m
saving the best model...
Epoch 23: 9.78409, Time is 1.75s
[34m[dev set Total] Prec.: 56.39, Rec.: 48.33, F1: 52.05[0m
saving the best model...
Epoch 24: 7.74745, Time is 1.79s
[34m[dev set Total] Prec.: 55.99, Rec.: 48.80, F1: 52.15[0m
saving the best model...
Epoch 25: 6.51245, Time is 1.87s
[34m[dev set Total] Prec.: 55.98, Rec.: 49.17, F1: 52.36[0m
saving the best model...
Epoch 26: 5.53001, Time is 1.87s
[34m[dev set Total] Prec.: 57.02, Rec.: 49.63, F1: 53.07[0m
saving the best model...
Epoch 27: 4.48135, Time is 2.00s
[34m[dev set Total] Prec.: 57.27, Rec.: 49.95, F1: 53.36[0m
saving the best model...
Epoch 28: 3.82030, Time is 1.82s
[34m[dev set Total] Prec.: 57.16, Rec.: 50.07, F1: 53.38[0m
saving the best model...
Epoch 29: 3.67110, Time is 2.12s
[34m[dev set Total] Prec.: 56.38, Rec.: 50.93, F1: 53.51[0m
saving the best model...
Epoch 30: 2.88510, Time is 1.88s
[34m[dev set Total] Prec.: 57.08, Rec.: 51.53, F1: 54.16[0m
saving the best model...
Epoch 31: 2.39288, Time is 1.90s
[34m[dev set Total] Prec.: 57.39, Rec.: 51.79, F1: 54.44[0m
saving the best model...
Epoch 32: 2.16782, Time is 1.85s
[34m[dev set Total] Prec.: 57.60, Rec.: 51.72, F1: 54.50[0m
saving the best model...
Epoch 33: 1.88457, Time is 1.93s
[34m[dev set Total] Prec.: 57.26, Rec.: 51.26, F1: 54.10[0m
Epoch 34: 1.69260, Time is 1.87s
[34m[dev set Total] Prec.: 57.83, Rec.: 51.30, F1: 54.37[0m
Epoch 35: 1.78589, Time is 1.98s
[34m[dev set Total] Prec.: 58.13, Rec.: 51.43, F1: 54.57[0m
saving the best model...
Epoch 36: 1.58191, Time is 1.92s
[34m[dev set Total] Prec.: 58.56, Rec.: 51.63, F1: 54.88[0m
saving the best model...
Epoch 37: 1.34690, Time is 1.82s
[34m[dev set Total] Prec.: 58.34, Rec.: 52.11, F1: 55.05[0m
saving the best model...
Epoch 38: 1.19946, Time is 1.87s
[34m[dev set Total] Prec.: 58.25, Rec.: 52.43, F1: 55.19[0m
saving the best model...
Epoch 39: 1.16782, Time is 1.86s
[34m[dev set Total] Prec.: 58.44, Rec.: 52.63, F1: 55.38[0m
saving the best model...
Epoch 40: 1.04343, Time is 1.91s
[34m[dev set Total] Prec.: 58.23, Rec.: 52.56, F1: 55.25[0m
Epoch 41: 1.06757, Time is 1.87s
[34m[dev set Total] Prec.: 57.69, Rec.: 52.66, F1: 55.06[0m
Epoch 42: 1.03577, Time is 1.73s
[34m[dev set Total] Prec.: 57.73, Rec.: 52.71, F1: 55.11[0m
Epoch 43: 0.92671, Time is 1.87s
[34m[dev set Total] Prec.: 57.80, Rec.: 52.54, F1: 55.05[0m
Epoch 44: 0.87817, Time is 1.86s
[34m[dev set Total] Prec.: 58.09, Rec.: 52.75, F1: 55.29[0m
Epoch 45: 0.86160, Time is 1.83s
[34m[dev set Total] Prec.: 57.96, Rec.: 52.78, F1: 55.25[0m
Epoch 46: 0.82410, Time is 1.89s
[34m[dev set Total] Prec.: 57.80, Rec.: 52.71, F1: 55.14[0m
Epoch 47: 0.77798, Time is 1.77s
[34m[dev set Total] Prec.: 57.89, Rec.: 52.76, F1: 55.21[0m
Epoch 48: 0.81641, Time is 1.89s
[34m[dev set Total] Prec.: 57.91, Rec.: 52.76, F1: 55.22[0m
Epoch 49: 0.80450, Time is 1.78s
[34m[dev set Total] Prec.: 57.87, Rec.: 52.69, F1: 55.16[0m
Epoch 50: 0.78727, Time is 1.81s
[34m[dev set Total] Prec.: 57.92, Rec.: 52.68, F1: 55.17[0m
Archiving the best Model...
Finished archiving the models
The best dev: 55.38
Final testing.
[34m[test set Total] Prec.: 56.08, Rec.: 49.75, F1: 52.73[0m
